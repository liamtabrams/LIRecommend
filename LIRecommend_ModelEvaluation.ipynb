{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before diving into model evaluation, I want to give a recap of what I've done to wrangle and engineer the dataset. The important thing to note is that I have tried two different feature engineering approaches. I will first explain the data scraping step and then I will explain the data processing for the two different feature engineering approaches following this data scraping/ initial collection step.\n",
        "\n",
        "Data scraping step: prior to writing any code, I made a spreadsheet where I went through job postings on LinkedIn and recorded the url for the job postings in one column and the rating I gave each one (0-3 based on how much I would want that job) in another. This spreadsheet has 107 rows. Then I wrote code to iterate over the urls in order to generate a text file for each one containing valuable information I was able to scrape from the job posting and concatenate together using the requests library and beautifulsoup. This information was the body text of the job posting and some other metadata like name of position, company, locale, industries, etc. included at the top of the text file.\n",
        "\n",
        "Feature Engineering Approach 1 (FANCY SCHMANCY):\n",
        "1. I wrote code to iterate over the generated text files and pipe this text into a prompt engineered to have ChatGPT output summaries for each text file in the form of a JSON file with specified categories as keys and lists of phrases as values.\n",
        "2. Once the JSON files were generated I could iterate over these to create a pandas dataframe with columns corresponding to the JSON dictionary keys. Thus each row of the resultant dataframe would essentially summarize the job posting. Remember, I had to reincorporate the labels back in with the data so 'rating' is also a column in this dataframe.\n",
        "3. Then, I wrote special logic to treat the data in certain columns categorically and create one-hot encodings for data in those columns, while most of the others I performed clustering on phrase embedding maps produced by aggregating all the data in those columns and passing it through a sentence transformer, and then counted frequencies of cluster labels in new cluster_count columns.\n",
        "4. Unused columns like the original columns containing phrases get dropped, and the dataframe gets passed through a supervised learning algorithm. I demonstrate and discuss results of that process herein, evaluating performance of different model architectures with different hyperparameter choices relevant to this feature extraction phase.\n",
        "\n",
        "Feature Engineering Approach 2 (RUDIMENTARY TFIDF):\n",
        "1. I essentially just started out with a dataframe with one column, which contained the text read from the text files containing data scraped for each job posting.\n",
        "2. I performed TFIDF vectorization on this one column, generating many more columns, and then passed the resultant dataframe (again reincorporating the 'rating' labels into another column and using that column as the target) to the same supervised learning algorithms that I tried for the first feature engineering approach, taking into consideration different hyperparameter choices for the TFIDF vectorization. I discuss results of that process and compare the results of the two feature engineering approaches.    "
      ],
      "metadata": {
        "id": "pjlAW1SOTdK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to create a dataframe from all the JSON summary files saved to my Google Drive."
      ],
      "metadata": {
        "id": "rxUS8JJJb6GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_files_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"employment_type\", \"job_function\", \"description_of_product/service\", \"industries\",\n",
        "              \"position_name\", \"broader_role_name\", \"company\", #\"location\", \"salary/compensation_range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name_of_department/team\", \"required_qualifications\",\n",
        "              \"preferred_qualifications\", \"benefits\", \"work_arrangement\", \"city\", \"state\", \"country\",\n",
        "              \"min_salary\", \"max_salary\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "locale_json_files_path = \"drive/MyDrive/jobLocations/\"\n",
        "salary_json_files_path = \"drive/MyDrive/jobSalaries/\"\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    #print(json_data)\n",
        "    field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info\n",
        "  else:\n",
        "    for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name == 'emploment_type':\n",
        "        column_name = 'employment_type'\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "  locale_json_file_path = os.path.join(locale_json_files_path, f'row{i}.json')\n",
        "  salary_json_file_path = os.path.join(salary_json_files_path, f'row{i}.json')\n",
        "  # Read locale JSON file\n",
        "  with open(locale_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  try:\n",
        "    city = json_data[\"city\"]\n",
        "    state = json_data[\"state\"]\n",
        "    country = json_data[\"country\"]\n",
        "    df.at[row_num, 'city'] = city\n",
        "    df.at[row_num, 'state'] = state\n",
        "    df.at[row_num, 'country'] = country\n",
        "  except:\n",
        "    df.at[row_num, 'city'] = \"N/A\"\n",
        "    df.at[row_num, 'state'] = \"N/A\"\n",
        "    df.at[row_num, 'country'] = \"N/A\"\n",
        "  # Read salary JSON file\n",
        "  with open(salary_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  min_salary = json_data[\"salary_min\"]\n",
        "  max_salary = json_data[\"salary_max\"]\n",
        "  df.at[row_num, 'min_salary'] = min_salary\n",
        "  df.at[row_num, 'max_salary'] = max_salary\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJAqBZbPcFxX",
        "outputId": "3d782ac0-433d-4ba6-a60d-333f5c0bde62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code runs the fancy feature engineering process (approach 1) on the data before training and evaluating the performance of a Linear Regression model."
      ],
      "metadata": {
        "id": "TpwfKK7GaD98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXeyZLTsTPV1",
        "outputId": "5ba8c1f7-9cff-47b9-de15-06e74cdc4289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-109-8c873f770565>:151: ConvergenceWarning: Number of distinct clusters (75) found smaller than n_clusters (79). Possibly due to duplicate points in X.\n",
            "  kmeans.fit(phrase_vecs_list)\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-109-8c873f770565>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-109-8c873f770565>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-109-8c873f770565>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[42, 27, 71, 64, 58, 69, 28, 37, 102, 46, 31, 75, 51, 93, 65, 6, 34, 38, 17, 76, 96, 81, 42, 27, 71, 64, 58, 69, 28, 37, 102, 46, 31, 75, 51, 93, 65, 6, 34, 38, 17, 76, 96, 81]\n",
            "['Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Part-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'On-site', 'N/A', 'REMOTE', 'remote', 'N/A', 'N/A', 'On-site', 'N/A', 'N/A', 'N/A', 'Onsite', 'Weekly hybrid onsite component', 'N/A', 'N/A', 'Remote', 'On-site', 'On-site', 'N/A', 'N/A', 'Onsite', 'N/A', 'Local remote']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 6, 3, 5, 5, 3, 3, 6, 3, 3, 3, 6, 2, 3, 3, 5, 6, 6, 3, 3, 6, 3, 5]\n",
            "got through feature engineering step\n",
            "Mean Absolute Error: 1713990052.7007072\n",
            "accuracy is 0.045454545454545456\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def feature_engineering_step(train_df, test_df):\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=400, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(400):\n",
        "    column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = common_clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  test_phrases = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    for index, value in test_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  n_clusters_scale_factor = {'city': .625, 'company': .94, 'name_of_department/team': .25}\n",
        "  singular_corpus_clusters_df_dict = {}\n",
        "  for col in singular_corpus_columns:\n",
        "    phrases = []\n",
        "    test_phrases = []\n",
        "    row_labels = []\n",
        "    test_row_labels = []\n",
        "    test_cluster_labels = []\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "    vector_col = f'{col}_vectors'\n",
        "    phrase_vecs_list = []\n",
        "    for i in train_df[vector_col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "    n_clusters = int(train_df.shape[0]*n_clusters_scale_factor[col])\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "    kmeans.fit(phrase_vecs_list)\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "      column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "      train_df[column_name] = 0  # Fill the column with zeros\n",
        "      test_df[column_name] = 0\n",
        "\n",
        "    cluster_labels = kmeans.labels_\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "    clusters_df = pd.DataFrame(data)\n",
        "    singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "    for i in range(row_labels[-1] + 1):\n",
        "      clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        train_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "    for index, value in test_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "    test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "    for i in range(test_row_labels[-1] + 1):\n",
        "      clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        test_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "\n",
        "  phrases = []\n",
        "  test_phrases = []\n",
        "  row_labels = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in work_arrangement_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(10):\n",
        "    column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = work_arrangement_clusters_df.loc[work_arrangement_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  for col in work_arrangement_columns:\n",
        "    for index, value in test_df[col].items():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  print(test_row_labels)\n",
        "  print(test_phrases)\n",
        "  print(test_cluster_labels)\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "df_copy = df.copy()\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df_copy[col])\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df_copy = pd.concat([df_copy, one_hot_encoded_df], axis=1)\n",
        "\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=507)\n",
        "\n",
        "train_df, test_df = feature_engineering_step(train_df, test_df)\n",
        "\n",
        "print('got through feature engineering step')\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "train_columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "test_columns_to_drop = columns_to_drop\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "train_df = train_df.drop(columns=train_columns_to_drop)\n",
        "test_df = test_df.drop(columns=test_columns_to_drop)\n",
        "train_df = train_df.drop(columns=[''])\n",
        "test_df = test_df.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in train_df.columns:\n",
        "  mode_val = train_df[col].mode()[0]\n",
        "  train_df[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "  if col in test_df.columns:\n",
        "    test_df[col].fillna(mode_val, inplace=True)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(test_df)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwOzsXrLnRqI",
        "outputId": "eb075d7b-b14e-472b-ed67-39b61098a1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.95319117e+00, -1.64982558e+09,  2.06118124e+00, -4.07070856e+08,\n",
              "        1.95319117e+00,  1.65079003e-01,  2.84838882e+00,  1.00002599e+00,\n",
              "       -5.11490388e+10,  5.05109598e+09, -2.01720169e+10,  2.06118124e+00,\n",
              "        1.33193870e+00,  2.08928929e+00,  1.69212827e+00,  2.06118124e+00,\n",
              "        4.48297080e+09, -1.80860825e+10,  1.90734220e+00,  2.06118124e+00,\n",
              "       -1.89942615e+10, -1.81146828e+10])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see for this particular train-test split, the linear regression model makes absurd predictions. Maybe we need to perform normalization on the data before passing it to the learning algorithm."
      ],
      "metadata": {
        "id": "IpJ9vawHn1xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_normalized_minmax = min_max_scaler.fit_transform(train_df)\n",
        "X_test_normalized_minmax = min_max_scaler.transform(test_df)\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train_normalized_minmax, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test_normalized_minmax)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPCmKkwIoKWS",
        "outputId": "2aa0042c-f986-467d-eedc-879273de6696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 1222531901985.8655\n",
            "accuracy is 0.22727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, that didn't help."
      ],
      "metadata": {
        "id": "C_ywESygoq59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in train_df.columns:\n",
        "  print(f\"Column: {column}\")\n",
        "  # Print value counts for the column\n",
        "  print(train_df[column].value_counts())\n",
        "  print()  # Print an empty line for readability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IQOXj2xovRC",
        "outputId": "297b2333-a466-49fd-d928-f32e93028211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: min_salary\n",
            "min_salary\n",
            "100.000    63\n",
            "150.000     3\n",
            "192.000     1\n",
            "137.500     1\n",
            "216.000     1\n",
            "101.000     1\n",
            "198.200     1\n",
            "115.000     1\n",
            "170.000     1\n",
            "58.300      1\n",
            "126.000     1\n",
            "107.000     1\n",
            "98.144      1\n",
            "117.000     1\n",
            "245.000     1\n",
            "129.000     1\n",
            "62.400      1\n",
            "90.000      1\n",
            "122.000     1\n",
            "120.000     1\n",
            "130.000     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: max_salary\n",
            "max_salary\n",
            "200.000    64\n",
            "170.000     2\n",
            "130.000     2\n",
            "220.000     2\n",
            "175.000     1\n",
            "216.646     1\n",
            "132.000     1\n",
            "93.600      1\n",
            "385.000     1\n",
            "173.000     1\n",
            "162.000     1\n",
            "189.000     1\n",
            "133.000     1\n",
            "288.000     1\n",
            "223.600     1\n",
            "297.300     1\n",
            "122.000     1\n",
            "414.000     1\n",
            "150.000     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: AR\n",
            "AR\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: AZ\n",
            "AZ\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: CA\n",
            "CA\n",
            "False    72\n",
            "True     13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: CO\n",
            "CO\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: FL\n",
            "FL\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: GA\n",
            "GA\n",
            "False    83\n",
            "True      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: IA\n",
            "IA\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: IL\n",
            "IL\n",
            "False    81\n",
            "True      4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: IN\n",
            "IN\n",
            "False    82\n",
            "True      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: MA\n",
            "MA\n",
            "False    78\n",
            "True      7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: MD\n",
            "MD\n",
            "False    82\n",
            "True      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: MI\n",
            "MI\n",
            "False    83\n",
            "True      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: MO\n",
            "MO\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: NC\n",
            "NC\n",
            "False    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: ND\n",
            "ND\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: NJ\n",
            "NJ\n",
            "False    82\n",
            "True      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: NY\n",
            "NY\n",
            "False    80\n",
            "True      5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: OR\n",
            "OR\n",
            "False    83\n",
            "True      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: PA\n",
            "PA\n",
            "False    82\n",
            "True      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: TX\n",
            "TX\n",
            "False    78\n",
            "True      7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: UT\n",
            "UT\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: VA\n",
            "VA\n",
            "False    84\n",
            "True      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: WA\n",
            "WA\n",
            "False    81\n",
            "True      4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: WI\n",
            "WI\n",
            "False    83\n",
            "True      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: USA\n",
            "USA\n",
            "True     71\n",
            "False    14\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: United States\n",
            "United States\n",
            "False    73\n",
            "True     12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster0_counts\n",
            "common_cluster0_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster1_counts\n",
            "common_cluster1_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster2_counts\n",
            "common_cluster2_counts\n",
            "0    70\n",
            "2     7\n",
            "3     4\n",
            "1     3\n",
            "4     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster3_counts\n",
            "common_cluster3_counts\n",
            "0    80\n",
            "1     4\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster4_counts\n",
            "common_cluster4_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster5_counts\n",
            "common_cluster5_counts\n",
            "0    73\n",
            "1    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster6_counts\n",
            "common_cluster6_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster7_counts\n",
            "common_cluster7_counts\n",
            "0    79\n",
            "1     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster8_counts\n",
            "common_cluster8_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster9_counts\n",
            "common_cluster9_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster10_counts\n",
            "common_cluster10_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster11_counts\n",
            "common_cluster11_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster12_counts\n",
            "common_cluster12_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster13_counts\n",
            "common_cluster13_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster14_counts\n",
            "common_cluster14_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster15_counts\n",
            "common_cluster15_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster16_counts\n",
            "common_cluster16_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster17_counts\n",
            "common_cluster17_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster18_counts\n",
            "common_cluster18_counts\n",
            "0    81\n",
            "1     2\n",
            "3     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster19_counts\n",
            "common_cluster19_counts\n",
            "0    79\n",
            "1     5\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster20_counts\n",
            "common_cluster20_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster21_counts\n",
            "common_cluster21_counts\n",
            "0    84\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster22_counts\n",
            "common_cluster22_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster23_counts\n",
            "common_cluster23_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster24_counts\n",
            "common_cluster24_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster25_counts\n",
            "common_cluster25_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster26_counts\n",
            "common_cluster26_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster27_counts\n",
            "common_cluster27_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster28_counts\n",
            "common_cluster28_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster29_counts\n",
            "common_cluster29_counts\n",
            "0    81\n",
            "1     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster30_counts\n",
            "common_cluster30_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster31_counts\n",
            "common_cluster31_counts\n",
            "0    82\n",
            "1     2\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster32_counts\n",
            "common_cluster32_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster33_counts\n",
            "common_cluster33_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster34_counts\n",
            "common_cluster34_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster35_counts\n",
            "common_cluster35_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster36_counts\n",
            "common_cluster36_counts\n",
            "0    80\n",
            "1     3\n",
            "2     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster37_counts\n",
            "common_cluster37_counts\n",
            "0    73\n",
            "1    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster38_counts\n",
            "common_cluster38_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster39_counts\n",
            "common_cluster39_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster40_counts\n",
            "common_cluster40_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster41_counts\n",
            "common_cluster41_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster42_counts\n",
            "common_cluster42_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster43_counts\n",
            "common_cluster43_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster44_counts\n",
            "common_cluster44_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster45_counts\n",
            "common_cluster45_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster46_counts\n",
            "common_cluster46_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster47_counts\n",
            "common_cluster47_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster48_counts\n",
            "common_cluster48_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster49_counts\n",
            "common_cluster49_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster50_counts\n",
            "common_cluster50_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster51_counts\n",
            "common_cluster51_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster52_counts\n",
            "common_cluster52_counts\n",
            "0    84\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster53_counts\n",
            "common_cluster53_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster54_counts\n",
            "common_cluster54_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster55_counts\n",
            "common_cluster55_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster56_counts\n",
            "common_cluster56_counts\n",
            "0    81\n",
            "1     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster57_counts\n",
            "common_cluster57_counts\n",
            "0    81\n",
            "1     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster58_counts\n",
            "common_cluster58_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster59_counts\n",
            "common_cluster59_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster60_counts\n",
            "common_cluster60_counts\n",
            "0    84\n",
            "4     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster61_counts\n",
            "common_cluster61_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster62_counts\n",
            "common_cluster62_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster63_counts\n",
            "common_cluster63_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster64_counts\n",
            "common_cluster64_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster65_counts\n",
            "common_cluster65_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster66_counts\n",
            "common_cluster66_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster67_counts\n",
            "common_cluster67_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster68_counts\n",
            "common_cluster68_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster69_counts\n",
            "common_cluster69_counts\n",
            "0    83\n",
            "2     1\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster70_counts\n",
            "common_cluster70_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster71_counts\n",
            "common_cluster71_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster72_counts\n",
            "common_cluster72_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster73_counts\n",
            "common_cluster73_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster74_counts\n",
            "common_cluster74_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster75_counts\n",
            "common_cluster75_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster76_counts\n",
            "common_cluster76_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster77_counts\n",
            "common_cluster77_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster78_counts\n",
            "common_cluster78_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster79_counts\n",
            "common_cluster79_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster80_counts\n",
            "common_cluster80_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster81_counts\n",
            "common_cluster81_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster82_counts\n",
            "common_cluster82_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster83_counts\n",
            "common_cluster83_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster84_counts\n",
            "common_cluster84_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster85_counts\n",
            "common_cluster85_counts\n",
            "0    83\n",
            "1     1\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster86_counts\n",
            "common_cluster86_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster87_counts\n",
            "common_cluster87_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster88_counts\n",
            "common_cluster88_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster89_counts\n",
            "common_cluster89_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster90_counts\n",
            "common_cluster90_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster91_counts\n",
            "common_cluster91_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster92_counts\n",
            "common_cluster92_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster93_counts\n",
            "common_cluster93_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster94_counts\n",
            "common_cluster94_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster95_counts\n",
            "common_cluster95_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster96_counts\n",
            "common_cluster96_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster97_counts\n",
            "common_cluster97_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster98_counts\n",
            "common_cluster98_counts\n",
            "0    81\n",
            "1     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster99_counts\n",
            "common_cluster99_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster100_counts\n",
            "common_cluster100_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster101_counts\n",
            "common_cluster101_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster102_counts\n",
            "common_cluster102_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster103_counts\n",
            "common_cluster103_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster104_counts\n",
            "common_cluster104_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster105_counts\n",
            "common_cluster105_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster106_counts\n",
            "common_cluster106_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster107_counts\n",
            "common_cluster107_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster108_counts\n",
            "common_cluster108_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster109_counts\n",
            "common_cluster109_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster110_counts\n",
            "common_cluster110_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster111_counts\n",
            "common_cluster111_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster112_counts\n",
            "common_cluster112_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster113_counts\n",
            "common_cluster113_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster114_counts\n",
            "common_cluster114_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster115_counts\n",
            "common_cluster115_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster116_counts\n",
            "common_cluster116_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster117_counts\n",
            "common_cluster117_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster118_counts\n",
            "common_cluster118_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster119_counts\n",
            "common_cluster119_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster120_counts\n",
            "common_cluster120_counts\n",
            "0    84\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster121_counts\n",
            "common_cluster121_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster122_counts\n",
            "common_cluster122_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster123_counts\n",
            "common_cluster123_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster124_counts\n",
            "common_cluster124_counts\n",
            "0    83\n",
            "2     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster125_counts\n",
            "common_cluster125_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster126_counts\n",
            "common_cluster126_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster127_counts\n",
            "common_cluster127_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster128_counts\n",
            "common_cluster128_counts\n",
            "0    83\n",
            "3     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster129_counts\n",
            "common_cluster129_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster130_counts\n",
            "common_cluster130_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster131_counts\n",
            "common_cluster131_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster132_counts\n",
            "common_cluster132_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster133_counts\n",
            "common_cluster133_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster134_counts\n",
            "common_cluster134_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster135_counts\n",
            "common_cluster135_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster136_counts\n",
            "common_cluster136_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster137_counts\n",
            "common_cluster137_counts\n",
            "0    82\n",
            "1     2\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster138_counts\n",
            "common_cluster138_counts\n",
            "0    82\n",
            "1     2\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster139_counts\n",
            "common_cluster139_counts\n",
            "0    81\n",
            "1     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster140_counts\n",
            "common_cluster140_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster141_counts\n",
            "common_cluster141_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster142_counts\n",
            "common_cluster142_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster143_counts\n",
            "common_cluster143_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster144_counts\n",
            "common_cluster144_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster145_counts\n",
            "common_cluster145_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster146_counts\n",
            "common_cluster146_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster147_counts\n",
            "common_cluster147_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster148_counts\n",
            "common_cluster148_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster149_counts\n",
            "common_cluster149_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster150_counts\n",
            "common_cluster150_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster151_counts\n",
            "common_cluster151_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster152_counts\n",
            "common_cluster152_counts\n",
            "0    83\n",
            "2     1\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster153_counts\n",
            "common_cluster153_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster154_counts\n",
            "common_cluster154_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster155_counts\n",
            "common_cluster155_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster156_counts\n",
            "common_cluster156_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster157_counts\n",
            "common_cluster157_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster158_counts\n",
            "common_cluster158_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster159_counts\n",
            "common_cluster159_counts\n",
            "0    83\n",
            "2     1\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster160_counts\n",
            "common_cluster160_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster161_counts\n",
            "common_cluster161_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster162_counts\n",
            "common_cluster162_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster163_counts\n",
            "common_cluster163_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster164_counts\n",
            "common_cluster164_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster165_counts\n",
            "common_cluster165_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster166_counts\n",
            "common_cluster166_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster167_counts\n",
            "common_cluster167_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster168_counts\n",
            "common_cluster168_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster169_counts\n",
            "common_cluster169_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster170_counts\n",
            "common_cluster170_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster171_counts\n",
            "common_cluster171_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster172_counts\n",
            "common_cluster172_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster173_counts\n",
            "common_cluster173_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster174_counts\n",
            "common_cluster174_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster175_counts\n",
            "common_cluster175_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster176_counts\n",
            "common_cluster176_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster177_counts\n",
            "common_cluster177_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster178_counts\n",
            "common_cluster178_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster179_counts\n",
            "common_cluster179_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster180_counts\n",
            "common_cluster180_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster181_counts\n",
            "common_cluster181_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster182_counts\n",
            "common_cluster182_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster183_counts\n",
            "common_cluster183_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster184_counts\n",
            "common_cluster184_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster185_counts\n",
            "common_cluster185_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster186_counts\n",
            "common_cluster186_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster187_counts\n",
            "common_cluster187_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster188_counts\n",
            "common_cluster188_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster189_counts\n",
            "common_cluster189_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster190_counts\n",
            "common_cluster190_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster191_counts\n",
            "common_cluster191_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster192_counts\n",
            "common_cluster192_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster193_counts\n",
            "common_cluster193_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster194_counts\n",
            "common_cluster194_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster195_counts\n",
            "common_cluster195_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster196_counts\n",
            "common_cluster196_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster197_counts\n",
            "common_cluster197_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster198_counts\n",
            "common_cluster198_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster199_counts\n",
            "common_cluster199_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster200_counts\n",
            "common_cluster200_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster201_counts\n",
            "common_cluster201_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster202_counts\n",
            "common_cluster202_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster203_counts\n",
            "common_cluster203_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster204_counts\n",
            "common_cluster204_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster205_counts\n",
            "common_cluster205_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster206_counts\n",
            "common_cluster206_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster207_counts\n",
            "common_cluster207_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster208_counts\n",
            "common_cluster208_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster209_counts\n",
            "common_cluster209_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster210_counts\n",
            "common_cluster210_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster211_counts\n",
            "common_cluster211_counts\n",
            "0    84\n",
            "4     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster212_counts\n",
            "common_cluster212_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster213_counts\n",
            "common_cluster213_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster214_counts\n",
            "common_cluster214_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster215_counts\n",
            "common_cluster215_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster216_counts\n",
            "common_cluster216_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster217_counts\n",
            "common_cluster217_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster218_counts\n",
            "common_cluster218_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster219_counts\n",
            "common_cluster219_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster220_counts\n",
            "common_cluster220_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster221_counts\n",
            "common_cluster221_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster222_counts\n",
            "common_cluster222_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster223_counts\n",
            "common_cluster223_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster224_counts\n",
            "common_cluster224_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster225_counts\n",
            "common_cluster225_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster226_counts\n",
            "common_cluster226_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster227_counts\n",
            "common_cluster227_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster228_counts\n",
            "common_cluster228_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster229_counts\n",
            "common_cluster229_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster230_counts\n",
            "common_cluster230_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster231_counts\n",
            "common_cluster231_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster232_counts\n",
            "common_cluster232_counts\n",
            "0    82\n",
            "1     2\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster233_counts\n",
            "common_cluster233_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster234_counts\n",
            "common_cluster234_counts\n",
            "0    82\n",
            "1     1\n",
            "2     1\n",
            "6     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster235_counts\n",
            "common_cluster235_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster236_counts\n",
            "common_cluster236_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster237_counts\n",
            "common_cluster237_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster238_counts\n",
            "common_cluster238_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster239_counts\n",
            "common_cluster239_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster240_counts\n",
            "common_cluster240_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster241_counts\n",
            "common_cluster241_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster242_counts\n",
            "common_cluster242_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster243_counts\n",
            "common_cluster243_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster244_counts\n",
            "common_cluster244_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster245_counts\n",
            "common_cluster245_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster246_counts\n",
            "common_cluster246_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster247_counts\n",
            "common_cluster247_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster248_counts\n",
            "common_cluster248_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster249_counts\n",
            "common_cluster249_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster250_counts\n",
            "common_cluster250_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster251_counts\n",
            "common_cluster251_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster252_counts\n",
            "common_cluster252_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster253_counts\n",
            "common_cluster253_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster254_counts\n",
            "common_cluster254_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster255_counts\n",
            "common_cluster255_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster256_counts\n",
            "common_cluster256_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster257_counts\n",
            "common_cluster257_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster258_counts\n",
            "common_cluster258_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster259_counts\n",
            "common_cluster259_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster260_counts\n",
            "common_cluster260_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster261_counts\n",
            "common_cluster261_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster262_counts\n",
            "common_cluster262_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster263_counts\n",
            "common_cluster263_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster264_counts\n",
            "common_cluster264_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster265_counts\n",
            "common_cluster265_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster266_counts\n",
            "common_cluster266_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster267_counts\n",
            "common_cluster267_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster268_counts\n",
            "common_cluster268_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster269_counts\n",
            "common_cluster269_counts\n",
            "0    83\n",
            "2     1\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster270_counts\n",
            "common_cluster270_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster271_counts\n",
            "common_cluster271_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster272_counts\n",
            "common_cluster272_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster273_counts\n",
            "common_cluster273_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster274_counts\n",
            "common_cluster274_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster275_counts\n",
            "common_cluster275_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster276_counts\n",
            "common_cluster276_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster277_counts\n",
            "common_cluster277_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster278_counts\n",
            "common_cluster278_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster279_counts\n",
            "common_cluster279_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster280_counts\n",
            "common_cluster280_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster281_counts\n",
            "common_cluster281_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster282_counts\n",
            "common_cluster282_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster283_counts\n",
            "common_cluster283_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster284_counts\n",
            "common_cluster284_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster285_counts\n",
            "common_cluster285_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster286_counts\n",
            "common_cluster286_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster287_counts\n",
            "common_cluster287_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster288_counts\n",
            "common_cluster288_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster289_counts\n",
            "common_cluster289_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster290_counts\n",
            "common_cluster290_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster291_counts\n",
            "common_cluster291_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster292_counts\n",
            "common_cluster292_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster293_counts\n",
            "common_cluster293_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster294_counts\n",
            "common_cluster294_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster295_counts\n",
            "common_cluster295_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster296_counts\n",
            "common_cluster296_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster297_counts\n",
            "common_cluster297_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster298_counts\n",
            "common_cluster298_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster299_counts\n",
            "common_cluster299_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster300_counts\n",
            "common_cluster300_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster301_counts\n",
            "common_cluster301_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster302_counts\n",
            "common_cluster302_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster303_counts\n",
            "common_cluster303_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster304_counts\n",
            "common_cluster304_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster305_counts\n",
            "common_cluster305_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster306_counts\n",
            "common_cluster306_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster307_counts\n",
            "common_cluster307_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster308_counts\n",
            "common_cluster308_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster309_counts\n",
            "common_cluster309_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster310_counts\n",
            "common_cluster310_counts\n",
            "0    83\n",
            "1     1\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster311_counts\n",
            "common_cluster311_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster312_counts\n",
            "common_cluster312_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster313_counts\n",
            "common_cluster313_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster314_counts\n",
            "common_cluster314_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster315_counts\n",
            "common_cluster315_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster316_counts\n",
            "common_cluster316_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster317_counts\n",
            "common_cluster317_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster318_counts\n",
            "common_cluster318_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster319_counts\n",
            "common_cluster319_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster320_counts\n",
            "common_cluster320_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster321_counts\n",
            "common_cluster321_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster322_counts\n",
            "common_cluster322_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster323_counts\n",
            "common_cluster323_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster324_counts\n",
            "common_cluster324_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster325_counts\n",
            "common_cluster325_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster326_counts\n",
            "common_cluster326_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster327_counts\n",
            "common_cluster327_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster328_counts\n",
            "common_cluster328_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster329_counts\n",
            "common_cluster329_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster330_counts\n",
            "common_cluster330_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster331_counts\n",
            "common_cluster331_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster332_counts\n",
            "common_cluster332_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster333_counts\n",
            "common_cluster333_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster334_counts\n",
            "common_cluster334_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster335_counts\n",
            "common_cluster335_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster336_counts\n",
            "common_cluster336_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster337_counts\n",
            "common_cluster337_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster338_counts\n",
            "common_cluster338_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster339_counts\n",
            "common_cluster339_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster340_counts\n",
            "common_cluster340_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster341_counts\n",
            "common_cluster341_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster342_counts\n",
            "common_cluster342_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster343_counts\n",
            "common_cluster343_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster344_counts\n",
            "common_cluster344_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster345_counts\n",
            "common_cluster345_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster346_counts\n",
            "common_cluster346_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster347_counts\n",
            "common_cluster347_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster348_counts\n",
            "common_cluster348_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster349_counts\n",
            "common_cluster349_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster350_counts\n",
            "common_cluster350_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster351_counts\n",
            "common_cluster351_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster352_counts\n",
            "common_cluster352_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster353_counts\n",
            "common_cluster353_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster354_counts\n",
            "common_cluster354_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster355_counts\n",
            "common_cluster355_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster356_counts\n",
            "common_cluster356_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster357_counts\n",
            "common_cluster357_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster358_counts\n",
            "common_cluster358_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster359_counts\n",
            "common_cluster359_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster360_counts\n",
            "common_cluster360_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster361_counts\n",
            "common_cluster361_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster362_counts\n",
            "common_cluster362_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster363_counts\n",
            "common_cluster363_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster364_counts\n",
            "common_cluster364_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster365_counts\n",
            "common_cluster365_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster366_counts\n",
            "common_cluster366_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster367_counts\n",
            "common_cluster367_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster368_counts\n",
            "common_cluster368_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster369_counts\n",
            "common_cluster369_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster370_counts\n",
            "common_cluster370_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster371_counts\n",
            "common_cluster371_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster372_counts\n",
            "common_cluster372_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster373_counts\n",
            "common_cluster373_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster374_counts\n",
            "common_cluster374_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster375_counts\n",
            "common_cluster375_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster376_counts\n",
            "common_cluster376_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster377_counts\n",
            "common_cluster377_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster378_counts\n",
            "common_cluster378_counts\n",
            "0    84\n",
            "3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster379_counts\n",
            "common_cluster379_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster380_counts\n",
            "common_cluster380_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster381_counts\n",
            "common_cluster381_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster382_counts\n",
            "common_cluster382_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster383_counts\n",
            "common_cluster383_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster384_counts\n",
            "common_cluster384_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster385_counts\n",
            "common_cluster385_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster386_counts\n",
            "common_cluster386_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster387_counts\n",
            "common_cluster387_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster388_counts\n",
            "common_cluster388_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster389_counts\n",
            "common_cluster389_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster390_counts\n",
            "common_cluster390_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster391_counts\n",
            "common_cluster391_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster392_counts\n",
            "common_cluster392_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster393_counts\n",
            "common_cluster393_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster394_counts\n",
            "common_cluster394_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster395_counts\n",
            "common_cluster395_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster396_counts\n",
            "common_cluster396_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster397_counts\n",
            "common_cluster397_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster398_counts\n",
            "common_cluster398_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: common_cluster399_counts\n",
            "common_cluster399_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster0_counts\n",
            "company_cluster0_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster1_counts\n",
            "company_cluster1_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster2_counts\n",
            "company_cluster2_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster3_counts\n",
            "company_cluster3_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster4_counts\n",
            "company_cluster4_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster5_counts\n",
            "company_cluster5_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster6_counts\n",
            "company_cluster6_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster7_counts\n",
            "company_cluster7_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster8_counts\n",
            "company_cluster8_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster9_counts\n",
            "company_cluster9_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster10_counts\n",
            "company_cluster10_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster11_counts\n",
            "company_cluster11_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster12_counts\n",
            "company_cluster12_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster13_counts\n",
            "company_cluster13_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster14_counts\n",
            "company_cluster14_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster15_counts\n",
            "company_cluster15_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster16_counts\n",
            "company_cluster16_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster17_counts\n",
            "company_cluster17_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster18_counts\n",
            "company_cluster18_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster19_counts\n",
            "company_cluster19_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster20_counts\n",
            "company_cluster20_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster21_counts\n",
            "company_cluster21_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster22_counts\n",
            "company_cluster22_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster23_counts\n",
            "company_cluster23_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster24_counts\n",
            "company_cluster24_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster25_counts\n",
            "company_cluster25_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster26_counts\n",
            "company_cluster26_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster27_counts\n",
            "company_cluster27_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster28_counts\n",
            "company_cluster28_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster29_counts\n",
            "company_cluster29_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster30_counts\n",
            "company_cluster30_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster31_counts\n",
            "company_cluster31_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster32_counts\n",
            "company_cluster32_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster33_counts\n",
            "company_cluster33_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster34_counts\n",
            "company_cluster34_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster35_counts\n",
            "company_cluster35_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster36_counts\n",
            "company_cluster36_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster37_counts\n",
            "company_cluster37_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster38_counts\n",
            "company_cluster38_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster39_counts\n",
            "company_cluster39_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster40_counts\n",
            "company_cluster40_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster41_counts\n",
            "company_cluster41_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster42_counts\n",
            "company_cluster42_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster43_counts\n",
            "company_cluster43_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster44_counts\n",
            "company_cluster44_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster45_counts\n",
            "company_cluster45_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster46_counts\n",
            "company_cluster46_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster47_counts\n",
            "company_cluster47_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster48_counts\n",
            "company_cluster48_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster49_counts\n",
            "company_cluster49_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster50_counts\n",
            "company_cluster50_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster51_counts\n",
            "company_cluster51_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster52_counts\n",
            "company_cluster52_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster53_counts\n",
            "company_cluster53_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster54_counts\n",
            "company_cluster54_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster55_counts\n",
            "company_cluster55_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster56_counts\n",
            "company_cluster56_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster57_counts\n",
            "company_cluster57_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster58_counts\n",
            "company_cluster58_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster59_counts\n",
            "company_cluster59_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster60_counts\n",
            "company_cluster60_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster61_counts\n",
            "company_cluster61_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster62_counts\n",
            "company_cluster62_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster63_counts\n",
            "company_cluster63_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster64_counts\n",
            "company_cluster64_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster65_counts\n",
            "company_cluster65_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster66_counts\n",
            "company_cluster66_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster67_counts\n",
            "company_cluster67_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster68_counts\n",
            "company_cluster68_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster69_counts\n",
            "company_cluster69_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster70_counts\n",
            "company_cluster70_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster71_counts\n",
            "company_cluster71_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster72_counts\n",
            "company_cluster72_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster73_counts\n",
            "company_cluster73_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster74_counts\n",
            "company_cluster74_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster75_counts\n",
            "company_cluster75_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster76_counts\n",
            "company_cluster76_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster77_counts\n",
            "company_cluster77_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: company_cluster78_counts\n",
            "company_cluster78_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster0_counts\n",
            "name_of_department/team_cluster0_counts\n",
            "0    73\n",
            "1    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster1_counts\n",
            "name_of_department/team_cluster1_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster2_counts\n",
            "name_of_department/team_cluster2_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster3_counts\n",
            "name_of_department/team_cluster3_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster4_counts\n",
            "name_of_department/team_cluster4_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster5_counts\n",
            "name_of_department/team_cluster5_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster6_counts\n",
            "name_of_department/team_cluster6_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster7_counts\n",
            "name_of_department/team_cluster7_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster8_counts\n",
            "name_of_department/team_cluster8_counts\n",
            "0    84\n",
            "2     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster9_counts\n",
            "name_of_department/team_cluster9_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster10_counts\n",
            "name_of_department/team_cluster10_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster11_counts\n",
            "name_of_department/team_cluster11_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster12_counts\n",
            "name_of_department/team_cluster12_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster13_counts\n",
            "name_of_department/team_cluster13_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster14_counts\n",
            "name_of_department/team_cluster14_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster15_counts\n",
            "name_of_department/team_cluster15_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster16_counts\n",
            "name_of_department/team_cluster16_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster17_counts\n",
            "name_of_department/team_cluster17_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster18_counts\n",
            "name_of_department/team_cluster18_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster19_counts\n",
            "name_of_department/team_cluster19_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: name_of_department/team_cluster20_counts\n",
            "name_of_department/team_cluster20_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster0_counts\n",
            "city_cluster0_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster1_counts\n",
            "city_cluster1_counts\n",
            "0    82\n",
            "1     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster2_counts\n",
            "city_cluster2_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster3_counts\n",
            "city_cluster3_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster4_counts\n",
            "city_cluster4_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster5_counts\n",
            "city_cluster5_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster6_counts\n",
            "city_cluster6_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster7_counts\n",
            "city_cluster7_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster8_counts\n",
            "city_cluster8_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster9_counts\n",
            "city_cluster9_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster10_counts\n",
            "city_cluster10_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster11_counts\n",
            "city_cluster11_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster12_counts\n",
            "city_cluster12_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster13_counts\n",
            "city_cluster13_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster14_counts\n",
            "city_cluster14_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster15_counts\n",
            "city_cluster15_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster16_counts\n",
            "city_cluster16_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster17_counts\n",
            "city_cluster17_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster18_counts\n",
            "city_cluster18_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster19_counts\n",
            "city_cluster19_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster20_counts\n",
            "city_cluster20_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster21_counts\n",
            "city_cluster21_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster22_counts\n",
            "city_cluster22_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster23_counts\n",
            "city_cluster23_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster24_counts\n",
            "city_cluster24_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster25_counts\n",
            "city_cluster25_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster26_counts\n",
            "city_cluster26_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster27_counts\n",
            "city_cluster27_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster28_counts\n",
            "city_cluster28_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster29_counts\n",
            "city_cluster29_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster30_counts\n",
            "city_cluster30_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster31_counts\n",
            "city_cluster31_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster32_counts\n",
            "city_cluster32_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster33_counts\n",
            "city_cluster33_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster34_counts\n",
            "city_cluster34_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster35_counts\n",
            "city_cluster35_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster36_counts\n",
            "city_cluster36_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster37_counts\n",
            "city_cluster37_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster38_counts\n",
            "city_cluster38_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster39_counts\n",
            "city_cluster39_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster40_counts\n",
            "city_cluster40_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster41_counts\n",
            "city_cluster41_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster42_counts\n",
            "city_cluster42_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster43_counts\n",
            "city_cluster43_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster44_counts\n",
            "city_cluster44_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster45_counts\n",
            "city_cluster45_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster46_counts\n",
            "city_cluster46_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster47_counts\n",
            "city_cluster47_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster48_counts\n",
            "city_cluster48_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster49_counts\n",
            "city_cluster49_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster50_counts\n",
            "city_cluster50_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster51_counts\n",
            "city_cluster51_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: city_cluster52_counts\n",
            "city_cluster52_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster0_counts\n",
            "work_arrangement_cluster0_counts\n",
            "0    80\n",
            "1     5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster1_counts\n",
            "work_arrangement_cluster1_counts\n",
            "0    65\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster2_counts\n",
            "work_arrangement_cluster2_counts\n",
            "0    75\n",
            "1    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster3_counts\n",
            "work_arrangement_cluster3_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster4_counts\n",
            "work_arrangement_cluster4_counts\n",
            "0    84\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster5_counts\n",
            "work_arrangement_cluster5_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster6_counts\n",
            "work_arrangement_cluster6_counts\n",
            "0    83\n",
            "1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster7_counts\n",
            "work_arrangement_cluster7_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster8_counts\n",
            "work_arrangement_cluster8_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: work_arrangement_cluster9_counts\n",
            "work_arrangement_cluster9_counts\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "DTPhVBkCl7ju",
        "outputId": "05a2624d-89a5-48ee-bc81-16f39d6c532f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    min_salary  max_salary     AR     AZ     CA     CO     FL     GA     IA  \\\n",
              "16       100.0       200.0  False  False  False  False  False  False  False   \n",
              "70       100.0       200.0  False  False  False  False  False  False  False   \n",
              "15       100.0       200.0  False  False  False  False  False  False  False   \n",
              "58       117.0       173.0  False  False  False  False  False  False  False   \n",
              "13       100.0       200.0  False  False  False  False  False  False  False   \n",
              "\n",
              "       IL  ...  work_arrangement_cluster0_counts  \\\n",
              "16   True  ...                                 0   \n",
              "70  False  ...                                 0   \n",
              "15  False  ...                                 0   \n",
              "58  False  ...                                 0   \n",
              "13  False  ...                                 0   \n",
              "\n",
              "    work_arrangement_cluster1_counts  work_arrangement_cluster2_counts  \\\n",
              "16                                 1                                 1   \n",
              "70                                 0                                 0   \n",
              "15                                 1                                 0   \n",
              "58                                 0                                 0   \n",
              "13                                 1                                 0   \n",
              "\n",
              "    work_arrangement_cluster3_counts  work_arrangement_cluster4_counts  \\\n",
              "16                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "15                                 1                                 0   \n",
              "58                                 0                                 0   \n",
              "13                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster5_counts  work_arrangement_cluster6_counts  \\\n",
              "16                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "15                                 0                                 0   \n",
              "58                                 0                                 0   \n",
              "13                                 0                                 1   \n",
              "\n",
              "    work_arrangement_cluster7_counts  work_arrangement_cluster8_counts  \\\n",
              "16                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "15                                 0                                 0   \n",
              "58                                 0                                 0   \n",
              "13                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster9_counts  \n",
              "16                                 0  \n",
              "70                                 0  \n",
              "15                                 0  \n",
              "58                                 0  \n",
              "13                                 0  \n",
              "\n",
              "[5 rows x 591 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88210cda-f8f1-4d6e-a3e6-f773e7407606\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>AR</th>\n",
              "      <th>AZ</th>\n",
              "      <th>CA</th>\n",
              "      <th>CO</th>\n",
              "      <th>FL</th>\n",
              "      <th>GA</th>\n",
              "      <th>IA</th>\n",
              "      <th>IL</th>\n",
              "      <th>...</th>\n",
              "      <th>work_arrangement_cluster0_counts</th>\n",
              "      <th>work_arrangement_cluster1_counts</th>\n",
              "      <th>work_arrangement_cluster2_counts</th>\n",
              "      <th>work_arrangement_cluster3_counts</th>\n",
              "      <th>work_arrangement_cluster4_counts</th>\n",
              "      <th>work_arrangement_cluster5_counts</th>\n",
              "      <th>work_arrangement_cluster6_counts</th>\n",
              "      <th>work_arrangement_cluster7_counts</th>\n",
              "      <th>work_arrangement_cluster8_counts</th>\n",
              "      <th>work_arrangement_cluster9_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>117.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 591 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88210cda-f8f1-4d6e-a3e6-f773e7407606')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88210cda-f8f1-4d6e-a3e6-f773e7407606 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88210cda-f8f1-4d6e-a3e6-f773e7407606');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-659e7d1a-4a9f-469e-8018-3a4df740fb9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-659e7d1a-4a9f-469e-8018-3a4df740fb9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-659e7d1a-4a9f-469e-8018-3a4df740fb9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: accuracy: .591\n",
        "mean absolute error: .614\n",
        "\n",
        "TT Split RS 95: Mean Absolute Error: 6277592985.598255\n",
        "accuracy is 0.22727272727272727\n",
        "\n",
        "TT Split RS 13: Mean Absolute Error: 11821743704.50261\n",
        "accuracy is 0.18181818181818182\n",
        "\n",
        "TT Split RS 21: Mean Absolute Error: 15975157405.285627\n",
        "accuracy is 0.2727272727272727\n",
        "\n",
        "TT Split RS 507: Mean Absolute Error: 1713990052.7007072\n",
        "accuracy is 0.045454545454545456"
      ],
      "metadata": {
        "id": "Td51peMbhikU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: We see that using a Linear Regression model where we round our predictions, using the \"fancy\" (maybe just dumb) feature engineering approach the way I did here yields an accuracy 59% and a MAE of .614. What do the results of Linear Regression predictions look like with the less fancy feature engineering approach (TFIDF)? We will look at that after we experiment with different models after having just done FE approach 1 and the chosen train-test split.\n",
        "\n",
        "Other train-test splits: we get absurd predictions from the linear regression model as shown above by the massive error values and horrible accuracy scores. We need to figure out why this is happening and try to get reasonable accuracy out of Linear Regression, because clearly something is wrong. We tried normalizing our data with MinMaxScaler as shown in one of the earlier code cells but we got horrendous results after doing that as well. Could dropping some columns help us? We saw earlier (when we were doing FE approach 1 but including phrases from the test set before doing the clustering) that what appeared to be a relatively well-performing linear regression model started showing results similar to what we are seeing now. Could either adding or dropping some columns get us the outcome we desire? To drop columns, we could drop cluster count columns or other columns with uninteresting distributions (which we tried earlier and saw linear regression start predicting wildly), and to add columns, we could for example increase our number of common corpus clusters from 400 to 500 and see what happens. Lastly, all of this has reminded me that I should probably try a LOGISTIC REGRESSION model next."
      ],
      "metadata": {
        "id": "GH7IvoK2rqvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "# By default, LogisticRegression uses OvR for multi-class classification\n",
        "model = LogisticRegression(max_iter=10000)  # Increase max_iter for convergence if needed\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(test_df)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i-NIru6IZmt",
        "outputId": "0ee3f5f6-f7e9-4cef-87ef-9b9742d6183d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "Mean Absolute Error: 0.45454545454545453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.4090909090909091\n",
        "Mean Absolute Error: 0.7727272727272727\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.4090909090909091\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5454545454545454\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.45454545454545453"
      ],
      "metadata": {
        "id": "IT8hb1ndMhaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree classifier on the training data\n",
        "clf.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNIs-uCAgN3o",
        "outputId": "54d2fa00-ba9a-400d-e761-4a6c803a309b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2727272727272727\n",
            "Mean Absolute Error: 1.1818181818181819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.54545\n",
        "Mean Absolute Error: .5\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.2727272727272727\n",
        "Mean Absolute Error: 1.1363636363636365\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5454545454545454\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.7272727272727273"
      ],
      "metadata": {
        "id": "HruXwpCAtQAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the Decision Tree with default hyperparameter values, Linear Regression had better accuracy (rounded predictions) but worse error on unrounded predictions for the train test split with random seed = 42."
      ],
      "metadata": {
        "id": "TuLaXpp2g1qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "rf_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhyqo_0-jPLw",
        "outputId": "02babbdc-cbbd-4cbf-d72a-2bc00d8ce148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "Mean Absolute Error: 0.5454545454545454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.591\n",
        "Mean Absolute Error: 0.454545\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.9090909090909091\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.4090909090909091\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5454545454545454"
      ],
      "metadata": {
        "id": "qwKzOKPcm6KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now try a HistGradientBoostingClassifier with our dialed in FE approach 1, just bc we are curious. I tried this earlier on our data prior to filling missing values with the mode of their column, because it actually worked even with the missing values, which Decision trees, random forest, and linear regression algorithms do not. When we trained the HistGradientBoostingClassifier on our data that had missing values, we got horrible accuracy at 32% and a pretty high MAE of .86."
      ],
      "metadata": {
        "id": "lA48uxnnhR24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# Initialize the HistGradientBoostingClassifier\n",
        "clf = HistGradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgbozhTWhJ1R",
        "outputId": "ca4e4e52-04cc-4a74-f3b7-1366498e823b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3181818181818182\n",
            "Mean Absolute Error: 0.9545454545454546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.6818181818181818\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.6818181818181818\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.6363636363636364\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.3181818181818182\n",
        "Mean Absolute Error: 0.9545454545454546"
      ],
      "metadata": {
        "id": "NZyfKy9-tsB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm is definitely doing better now, but not as well as any of the others I've tried."
      ],
      "metadata": {
        "id": "T1VqcLrzkJFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now try XGBoost with our data. We tried it before with our earlier invalid version of FE Approach 1 and got accuracy of 45%, MAE of .72. Second worst to HistGradientBoostingClassifier. How much better does it do now?"
      ],
      "metadata": {
        "id": "aArcL0uuka8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "Rbl7sk6SkQdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8934c671-bb70-4f66-8326-b0a386cf080f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = xgb_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7wnOOdmqd71",
        "outputId": "d9c20fa5-d4dd-427e-bff3-0a06ef51a28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "Mean Absolute Error: 0.5454545454545454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.5\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.4090909090909091\n",
        "Mean Absolute Error: 0.8636363636363636\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.6818181818181818\n",
        "Mean Absolute Error: 0.36363636363636365\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5454545454545454"
      ],
      "metadata": {
        "id": "_p8HYBGlt6Ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WNsLibEft3E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! So we got decent accuracy at nearly 64% and an MAE of .5 with XGBoost (first train-test split). Let's try some other parameters to pass to the XGBClassifier object."
      ],
      "metadata": {
        "id": "rGiECAz9usvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = xgb_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYU5OMoZu6QI",
        "outputId": "b05061fc-63fb-49ed-ab27-588ea578c144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4090909090909091\n",
            "Mean Absolute Error: 0.8636363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, that didn't change our results at all. We want to perform grid searches on the hyperparameter spaces for the Decision Tree, Random Forest, and XGBoost algorithms."
      ],
      "metadata": {
        "id": "yM3ARGJvvZVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],     # Minimum number of samples required to be at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(train_df, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_dt_classifier = grid_search.best_estimator_\n",
        "y_pred = best_dt_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg1VDJK_vw86",
        "outputId": "4a111f10-cd66-4452-a6f0-aa7065b067a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Accuracy: 0.5454545454545454\n",
            "Mean Absolute Error: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even after finding the best estimator, the decision tree algorithm gives the same accuracy and MAE against the test set. We can probably rule out a decision tree as being the best model for our motives. Let's see if we can squeeze out anything better than 59% accuracy and .45 MAE from the Random Forest Classifier using a grid search."
      ],
      "metadata": {
        "id": "Eh3kH1OQw7qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],        # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],             # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10],         # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],           # Minimum number of samples required to be at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'] # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(train_df, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred = best_rf_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvaTxpsCxbAy",
        "outputId": "5b723ce2-9b64-4f48-d229-721abe6a5371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "Accuracy: 0.5909090909090909\n",
            "Mean Absolute Error: 0.45454545454545453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like the decision tree, hyperparameter grid search didn't find us an estimator with better accuracy than we've already seen. Now we will perform a grid search for XGBoost."
      ],
      "metadata": {
        "id": "37yY2vhk5_25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'subsample': [0.5, 1.0],\n",
        "    'colsample_bytree': [0.5, 1.0],\n",
        "    'reg_lambda': [1, 10, 100],\n",
        "    'reg_alpha': [0, 1, 10]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(train_df, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred = best_rf_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JabKy4AD6V1e",
        "outputId": "00716661-8f33-46c4-fc0a-5bd18eb79f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1.0}\n",
            "Accuracy: 0.5909090909090909\n",
            "Mean Absolute Error: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though XGBoost had an accuracy of almost 64% against our test set from our chosen seed for the train-test split, cross validation calculated the best estimator as having an accuracy of only 59%."
      ],
      "metadata": {
        "id": "8Lzd3SomaUD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also tried a Support Vector Machine algorithm:"
      ],
      "metadata": {
        "id": "z7sEwRNma0V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_df)\n",
        "X_test_scaled = scaler.transform(test_df)\n",
        "\n",
        "# Step 4: Initialize and Train the SVM Classifier\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # Example hyperparameters\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Classifier\n",
        "accuracy = svm_classifier.score(X_test_scaled, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4i31oVoa6AJ",
        "outputId": "f721a291-d0e4-48fe-ccc9-df0659a29760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: .54545\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5\n",
        "\n",
        "TT Split RS 13: Accuracy: .590909\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.45454545454545453\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453"
      ],
      "metadata": {
        "id": "l_cgkHqB2mma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So same accuracy as before when we did the feature engineering incorrectly. Note that there isn't an easy or built-in way to calculate mean error for the particular implementation of SVC that we used."
      ],
      "metadata": {
        "id": "w3O5tcbxbPN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also tried KNeighborsClassifier and KNeighborsRegressor algorithms."
      ],
      "metadata": {
        "id": "bwtc3WPEb6E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the classifier\n",
        "knn_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the regressor\n",
        "knn_regressor.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_regressor.predict(test_df)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Evaluate the mean squared error of the regressor\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNA389PNazju",
        "outputId": "9cc1086c-6dd3-4411-8b8e-b590a8562de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4090909090909091\n",
            "Mean absolute Error: 0.9090909090909091\n",
            "Accuracy: 0.36363636363636365\n",
            "Mean absolute Error: 0.7090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the KNN regressor did better on accuracy after its predictions are rounded but the classifier did better on error for TT SPLIT RS 42.\n",
        "\n",
        "KNNC\n",
        "KNNR\n",
        "TT Split RS 42: Accuracy: .54545\n",
        "Mean Absolute Error: .5\n",
        "Accuracy: .591\n",
        "Mean Absolute Error: .518\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.8181818181818182\n",
        "Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.8181818181818182\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5\n",
        "Mean absolute Error: 0.6818181818181818\n",
        "Accuracy: 0.5\n",
        "Mean absolute Error: 0.5727272727272726\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "Mean absolute Error: 0.5454545454545454\n",
        "Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.6727272727272728\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.4090909090909091\n",
        "Mean absolute Error: 0.9090909090909091\n",
        "Accuracy: 0.36363636363636365\n",
        "Mean absolute Error: 0.7090909090909091\n",
        "\n",
        "Lastly, we tried a Gaussian Naive Bayes algorithm."
      ],
      "metadata": {
        "id": "q__8aez6ceAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Step 3: Initialize and Train the GNB Classifier\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(train_df, y_train)  # Convert sparse matrix to dense array for GNB\n",
        "\n",
        "# Step 4: Evaluate the Classifier\n",
        "y_pred = gnb_classifier.predict(test_df)  # Convert sparse matrix to dense array for prediction\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvGxIlXgc2Jk",
        "outputId": "64f89e77-31a4-49e7-a467-c71c8b345f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4090909090909091\n",
            "Mean absolute error: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42:\n",
        "Accuracy: 0.36363636363636365\n",
        "Mean absolute error: .7727\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.22727272727272727\n",
        "Mean absolute error: 1.1818181818181819\n",
        "\n",
        "TT Split RS 13:\n",
        "Accuracy: 0.36363636363636365\n",
        "Mean absolute error: 1.0\n",
        "\n",
        "TT Split RS 21:\n",
        "Accuracy: 0.18181818181818182\n",
        "Mean absolute error: 1.2727272727272727\n",
        "\n",
        "TT Split RS 507:\n",
        "Accuracy: 0.4090909090909091\n",
        "Mean absolute error: 0.7727272727272727"
      ],
      "metadata": {
        "id": "Alsx7IwZ3IQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, GaussianNB does quite awfully."
      ],
      "metadata": {
        "id": "OS1KJwrmdEYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"posting_text\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  text_file_path = f'drive/MyDrive/text_files2/row{i}.txt'\n",
        "  with open(text_file_path, 'r') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    file_contents = file.read()\n",
        "  df.at[row_num, 'posting_text'] = file_contents\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JShsHrsIs9CB",
        "outputId": "d78679b1-48f0-4d5c-83df-c3593c45f795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataframe is named 'df' and the text column is named 'job_posting_text'\n",
        "\n",
        "# Step 1: Split your data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['posting_text'], df['rating'], test_size=0.2, random_state=507)\n",
        "\n",
        "# Step 2: Initialize and fit TF-IDF vectorizer on the training data only\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Step 3: Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Now you have X_train_tfidf and X_test_tfidf ready to be used with your model for training and evaluation."
      ],
      "metadata": {
        "id": "UjnOqjvMu_DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically, we are going to try a bunch of different models and see what the performance looks like for this much simpler feature engineering approach that only analyzes the text from the job postings using TFIDF, starting with linear regression."
      ],
      "metadata": {
        "id": "BKI9wb03iiA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test.tolist(), y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKbGMYravC-Y",
        "outputId": "110e4544-639b-4060-ef8e-2ea2b5f9efd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.5222678485765134\n",
            "accuracy is 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So using Linear Regression again except with our data that we feature engineered with approach #2, our predictions give an accuracy of 55% (when rounded) and a mean absolute error of .48. It is interesting that the accuracy of this model is worse but the MAE is lower compared to feature engineering approach #1, for train-test split random seed 42."
      ],
      "metadata": {
        "id": "yl4sfUQkvEeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Mean Absolute Error: 0.48080695505940163\n",
        "accuracy is 0.5454545454545454\n",
        "\n",
        "TT Split RS 95: Mean Absolute Error: 0.5589456133684491\n",
        "accuracy is 0.45454545454545453\n",
        "\n",
        "TT Split RS 13: Mean Absolute Error: 0.4983688602870732\n",
        "accuracy is 0.5\n",
        "\n",
        "TT Split RS 21: Mean Absolute Error: 0.45019354415526897\n",
        "accuracy is 0.5909090909090909\n",
        "\n",
        "TT Split RS 507: Mean Absolute Error: 0.5222678485765134\n",
        "accuracy is 0.5"
      ],
      "metadata": {
        "id": "pXvldyBa3umb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "# By default, LogisticRegression uses OvR for multi-class classification\n",
        "model = LogisticRegression(max_iter=1000)  # Increase max_iter for convergence if needed\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17wei0iFERp3",
        "outputId": "05628cf9-910d-4e41-838d-9874e7206c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45454545454545453\n",
            "Mean Absolute Error: 0.6363636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5454545454545454\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.6363636363636364"
      ],
      "metadata": {
        "id": "LeOy8qk2Eo93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "CCjB6Mt6GdV4",
        "outputId": "d4b6093d-cd03-4fd3-ebcc-7df497da7461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f16de795e416>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Evaluate the performance of the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are getting an error, likely because we need to one-hot encode the target classes. Maybe RandomForestRegressor will work straight away."
      ],
      "metadata": {
        "id": "Iq8yUaPQGvKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anyway, I added in some code to label encode the rating data to evaluate an RFC model together with FE approach 2 which is purely TFIDF based."
      ],
      "metadata": {
        "id": "uwBAABAgqfJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestRegressor(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test.tolist(), y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vhD5iyeGwUg",
        "outputId": "98435c68-e42e-4731-9868-a76a45e9ca23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae: 0.618030303030303\n",
            "[1.55       0.7        1.59666667 1.74       2.59333333 2.1\n",
            " 1.9        1.17       2.24666667 2.09333333 1.49       2.22666667\n",
            " 1.91333333 1.21       1.94       2.22       1.72       2.49333333\n",
            " 1.74333333 2.42       1.61666667 2.14666667]\n",
            "accuracy is 0.45454545454545453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: .5\n",
        "Mean Absolute Error: .5024242424242424\n",
        "\n",
        "TT Split RS 95: Accuracy: .5454545454545454\n",
        "Mean Absolute Error: .5603030303030303\n",
        "\n",
        "TT Split RS 13: Accuracy: .5454545454545454\n",
        "Mean Absolute Error: .5413636363636363\n",
        "\n",
        "TT Split RS 21: Accuracy: .5\n",
        "Mean Absolute Error: .521060606060606\n",
        "\n",
        "TT Split RS 507: Accuracy: .45454545454545453\n",
        "Mean Absolute Error: .618030303030303\n"
      ],
      "metadata": {
        "id": "203VlpJH31Ez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the RandomForestRegressor model with FE approach 2 gives us an accuracy of rounded predictions of 50% and MAE of .502, which is worse than the RandomForestClassifier combined with FE approach 1."
      ],
      "metadata": {
        "id": "iqJDMku0Hecz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMFK9XGQkBon",
        "outputId": "62654890-971b-4d30-e59d-d3ad762842a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "[1 0 3 3 3 2 1 2 2 3 2 3 2 1 2 2 0 3 2 2 3 2]\n",
            "Accuracy: 0.5\n",
            "mae: 0.5909090909090909\n",
            "[2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazingly, the random forest classifier gives us the exact same accuracy on the chosen test set (RS 42) whether we performed FE Approach 1 or 2."
      ],
      "metadata": {
        "id": "9ZAeFXROkJyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "mae: 0.45454545454545453\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5454545454545454\n",
        "mae: 0.6363636363636364\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5909090909090909\n",
        "mae: 0.4090909090909091\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "mae: 0.5454545454545454\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5\n",
        "mae: 0.5909090909090909"
      ],
      "metadata": {
        "id": "hmLnSckw3_9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree classifier on the training data\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZopGNYDkixu",
        "outputId": "fc12ccad-3c7f-473e-dbf5-26076432ae3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6363636363636364\n",
            "Mean Absolute Error: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the decision tree does worse with feature engineering approach 2 on RS 42."
      ],
      "metadata": {
        "id": "OZEHj10slA8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.6363636363636364\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.6363636363636364\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.3181818181818182\n",
        "Mean Absolute Error: 0.8636363636363636\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.4090909090909091\n",
        "Mean Absolute Error: 0.6818181818181818\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.5"
      ],
      "metadata": {
        "id": "oCOj3uqd4Kwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = xgb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8vF9REAlFQi",
        "outputId": "48af8cb5-6d75-468e-c53a-d48a6f1b1f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4090909090909091\n",
            "Mean Absolute Error: 0.6363636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also interestingly, the MAE is the same for XGBoost algorithm but the accuracy is slightly lower."
      ],
      "metadata": {
        "id": "oq2T5kTnlca-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5454545454545454\n",
        "Mean Absolute Error: 0.5\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.36363636363636365\n",
        "Mean Absolute Error: 0.7272727272727273\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.45454545454545453\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.4090909090909091\n",
        "Mean Absolute Error: 0.6363636363636364"
      ],
      "metadata": {
        "id": "rI9xKEeO4Pa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Step 4: Initialize and Train the SVM Classifier\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # Example hyperparameters\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Classifier\n",
        "accuracy = svm_classifier.score(X_test_tfidf, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1PUdcRllrp0",
        "outputId": "10b57e9d-bcca-43f0-dd33-5ab5fa484a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45454545454545453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this feature engineering approach, we got the exact same prediction accuracy for the support vector machine algorithm."
      ],
      "metadata": {
        "id": "iw-N8pKSmHRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5454545454545454\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5454545454545454\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5909090909090909\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453"
      ],
      "metadata": {
        "id": "hADOdIEz4Tjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# Initialize the HistGradientBoostingClassifier\n",
        "clf = HistGradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train_tfidf.toarray(), y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test_tfidf.toarray())\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc2Ec-cmmSap",
        "outputId": "7a916c1a-88ba-4be6-e8c8-8da6a24156b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Mean Absolute Error: 0.5909090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.7272727272727273\n",
        "Mean Absolute Error: 0.3181818181818182\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.4090909090909091\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.36363636363636365\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5909090909090909"
      ],
      "metadata": {
        "id": "-M3Yyo6H4bDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qluj894lxD4j",
        "outputId": "6e76e477-46cd-4bbe-9de9-9722a3e86a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'categorical_features': None, 'class_weight': None, 'early_stopping': 'auto', 'interaction_cst': None, 'l2_regularization': 0.0, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_bins': 255, 'max_depth': None, 'max_iter': 100, 'max_leaf_nodes': 31, 'min_samples_leaf': 20, 'monotonic_cst': None, 'n_iter_no_change': 10, 'random_state': None, 'scoring': 'loss', 'tol': 1e-07, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I saw this MY JAWS DROPPED! HOLY MOTHER OF PEARL! I didn't think I would get such great results combining HistGradientBoostingClassifier with feature engineering approach 2! I literally just did it for shits and giggles and to say I tried it. Wow. I'm going to have to examine these results more closely because this is by far the best performance I have gotten out of any of the models. LOOK AT THAT MEAN ABSOLUTE ERROR!"
      ],
      "metadata": {
        "id": "eWcBSAdomzrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYShlEtRnUNc",
        "outputId": "0cb6ba5c-abb7-4db1-83a2-6f94e8d3a61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 1 2 2 0 2 2 3 3 2 2 1 2 3 2 1 3 2 1 2 1]\n",
            "[2 2 2 2 2 0 2 2 2 3 2 2 2 2 3 2 1 2 2 2 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is rather amazing."
      ],
      "metadata": {
        "id": "hhySKBYenekk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to perform a grid search cross-validation to A) be more confident in believing what I'm seeing and B) see if we can get even better results from hyperparameter tuning. Because this can take forever, I'm only going to try two values per parameter in the search."
      ],
      "metadata": {
        "id": "JRKfucWyoB7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'max_iter': [100, 300],\n",
        "    'max_depth': [3, 7],\n",
        "    'min_samples_leaf': [1, 4],\n",
        "    # Add more hyperparameters as needed\n",
        "}\n",
        "\n",
        "# Instantiate HistGradientBoostingClassifier\n",
        "clf = HistGradientBoostingClassifier()\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train_tfidf.toarray(), y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_classifier = grid_search.best_estimator_\n",
        "y_pred = best_classifier.predict(X_test_tfidf.toarray())\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC9S-yewoNi3",
        "outputId": "80ea4dd2-752d-438a-8397-bdf210685b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 7, 'max_iter': 300, 'min_samples_leaf': 4}\n",
            "Accuracy: 0.45454545454545453\n",
            "Mean Absolute Error: 0.6818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, we got very poor results from doing this grid search. We should change our param grid to contain the point used by the default invocation of HistGradientBoostingClassifier which gave us the values of accuracy and MAE that initially got us excited. That point has coordinates:\n",
        "'learning_rate': .1\n",
        "'max_iter': 100\n",
        "'max_depth': None\n",
        "'min_samples_leaf': 20"
      ],
      "metadata": {
        "id": "ZeVUGNLljoc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Step 3: Initialize and Train the GNB Classifier\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(X_train_tfidf.toarray(), y_train)  # Convert sparse matrix to dense array for GNB\n",
        "\n",
        "# Step 4: Evaluate the Classifier\n",
        "y_pred = gnb_classifier.predict(X_test_tfidf.toarray())  # Convert sparse matrix to dense array for prediction\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)"
      ],
      "metadata": {
        "id": "VGRLnIl3pcNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb8c7d0-8e4b-493b-e7ae-3607bfb52c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5909090909090909\n",
            "Mean absolute error: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5\n",
        "Mean absolute error: 0.5454545454545454\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5909090909090909\n",
        "Mean absolute error: 0.6363636363636364\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5\n",
        "Mean absolute error: 0.5909090909090909\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5454545454545454\n",
        "Mean absolute error: 0.5\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5909090909090909\n",
        "Mean absolute error: 0.5"
      ],
      "metadata": {
        "id": "hD3klddi4kNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the classifier\n",
        "knn_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the regressor\n",
        "knn_regressor.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_regressor.predict(test_df)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Evaluate the mean squared error of the regressor\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqebmTVw4m26",
        "outputId": "4f605c66-0c43-4878-f65d-1a1db3914d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4090909090909091\n",
            "Mean absolute Error: 0.6363636363636364\n",
            "Accuracy: 0.36363636363636365\n",
            "Mean absolute Error: 0.7090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "Mean absolute Error: 0.5\n",
        "Accuracy: 0.4090909090909091\n",
        "Mean absolute Error: 0.7272727272727273\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5909090909090909\n",
        "Mean absolute Error: 0.5909090909090909\n",
        "Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.7727272727272727\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.6363636363636364\n",
        "Mean absolute Error: 0.36363636363636365\n",
        "Accuracy: 0.22727272727272727\n",
        "Mean absolute Error: 0.8181818181818182\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5454545454545454\n",
        "Mean absolute Error: 0.5\n",
        "Accuracy: 0.5454545454545454\n",
        "Mean absolute Error: 0.6454545454545455\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.4090909090909091\n",
        "Mean absolute Error: 0.6363636363636364\n",
        "Accuracy: 0.36363636363636365\n",
        "Mean absolute Error: 0.7090909090909091"
      ],
      "metadata": {
        "id": "lI10kBLK5aq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To give a little bit more context and info, when I first started training and evaluating models against my data, I tried a handful of different types of models together with FE approach 1, and found that Linear Regression gave me the best performance at 68% accuracy and about .45 MAE. However, I was including phrases from the test set in the embedding maps before identifying and counting clusters, meaning language from the test set was used to train the model, which is a big no-no aka cheating in a supervised learning problem. While I was getting better performance from LR using the invalid FE approach, I was getting the same performance in terms of accuracy from tree-based models including Random Forest Classifier that I did when doing FE approach 1 correctly."
      ],
      "metadata": {
        "id": "JWkGO0qCJNRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have formed a hypothesis which is partially based on the observation that linear regression had noticeably better accuracy when we did FE approach 1 but with phrases from our test group influencing our clustering, which was not valid. We got an accuracy of 68% (rounded predictions) and an MAE of roughly .45 using 500 clusters for our common corpus. However, when we removed the salary columns from the data having gone through FE approach 1 because we wanted to compare results to FE approach 2 based only on representations of our text to see if TFIDF or phrase embedding clustering would prove better, linear regression drastically failed and made wild predictions which were nowhere in the ballpark of 0-3 (they could be orders of magnitude larger or smaller). Linear regression completely exploded without the salary columns acting as some kind of glue for the algorithm to work meaningfully well, when we did FE Approach 1. However, with FE approach 2, LR did reasonably well at 59% although the MAE was .61. So I am thinking, what if we combined feature engineering approaches 1 and 2, where we perform the TFIDF vectorization but we also include salary columns in the X dataframe, and see how linear regression does? We can also see if random forest performs differently, although I think we observed that removing the salary columns didn't change anything or had negligible effects on the predictions of random forest, though I say that somewhat unconfidently."
      ],
      "metadata": {
        "id": "R0Bg5znwu40Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what I need to do now is use a different name for the dataframe I make with FE approach 2 and then combine that dataframe with just the salary columns from the FE approach 1 dataframe."
      ],
      "metadata": {
        "id": "8VDBc79uzw2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "vYbHkwA10DRS",
        "outputId": "2699e297-820f-422e-a27e-76216a7650ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country  min_salary  max_salary  rating  \n",
              "0            Redmond    WA            USA        62.4        93.6       1  \n",
              "1           New York        United States         NaN         NaN       2  \n",
              "2      North Reading    MA            USA         NaN         NaN       2  \n",
              "3      San Francisco    CA            USA       150.0       200.0       3  \n",
              "4  Dallas-Fort Worth    TX            USA         NaN         NaN       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b21994d4-eea0-4efc-a8e5-266b667e5394\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b21994d4-eea0-4efc-a8e5-266b667e5394')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b21994d4-eea0-4efc-a8e5-266b667e5394 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b21994d4-eea0-4efc-a8e5-266b667e5394');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9c75c51-d7dc-499c-819f-c81a28240bfe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9c75c51-d7dc-499c-819f-c81a28240bfe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9c75c51-d7dc-499c-819f-c81a28240bfe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"San Antonio\",\n          \"Santa Rosa\",\n          \"Redmond\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"VA\",\n          \"FL\",\n          \"WA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"USA\",\n          \"United States\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.0285584779617,\n        \"min\": 58.3,\n        \"max\": 245.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          170.0,\n          175.0,\n          62.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78.08504978928872,\n        \"min\": 90.0,\n        \"max\": 414.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          236.0,\n          170.0,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool, so we don't actually have to run code that is tied up with all the phrase embedding and clustering stuff which takes a long time. We can get it straight from df. So replace 'df' with 'df2' in the code that generates that dataframe with 'posting_text' and 'rating', from FE approach 2."
      ],
      "metadata": {
        "id": "8E3qMIaC0O9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"posting_text\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df2 = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df2.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  text_file_path = f'drive/MyDrive/text_files2/row{i}.txt'\n",
        "  with open(text_file_path, 'r') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    file_contents = file.read()\n",
        "  df2.at[row_num, 'posting_text'] = file_contents\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df2.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df2.replace('N/A', np.nan, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzNVdtQ00tY_",
        "outputId": "0b3b6f6f-f198-4325-dc12-948339acca36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_df = df[['min_salary', 'max_salary']]\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in salary_df.columns:\n",
        "  mode_val = salary_df[col].mode()[0]\n",
        "  salary_df[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "concatenated_df = pd.concat([df2, salary_df], axis=1)\n",
        "\n",
        "print(concatenated_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RofWCoZJ1kh4",
        "outputId": "829d99ca-799a-4468-c196-f31a36423136"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posting_text    0\n",
            "rating          0\n",
            "min_salary      0\n",
            "max_salary      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-fb64bb74c5be>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  salary_df[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataframe is named 'df' and the text column is named 'job_posting_text'\n",
        "\n",
        "# Step 1: Split your data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(concatenated_df[['posting_text', 'min_salary', 'max_salary']], concatenated_df['rating'], test_size=0.2, random_state=507)\n",
        "\n",
        "# Step 2: Initialize and fit TF-IDF vectorizer on the training data only\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['posting_text'])\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=X_train.index)\n",
        "\n",
        "# Step 3: Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test['posting_text'])\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=X_test.index)\n",
        "\n",
        "new_df = X_train.drop(columns='posting_text')\n",
        "new_test_df = X_test.drop(columns='posting_text')\n",
        "X_train = pd.concat([new_df, X_train_tfidf_df], axis=1)\n",
        "X_test = pd.concat([new_test_df, X_test_tfidf_df], axis=1)\n",
        "\n",
        "\n",
        "# Now you have X_train and X_test ready to be used with your model for training and evaluation."
      ],
      "metadata": {
        "id": "j4uUfO-d2OkG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "gngC-_jp-3N2",
        "outputId": "3827e49f-9036-4328-8451-f2df7f25dc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    min_salary  max_salary        00       000  000remote  004  \\\n",
              "67       100.0       200.0  0.000000  0.000000        0.0  0.0   \n",
              "26       100.0       200.0  0.069401  0.071417        0.0  0.0   \n",
              "22       100.0       200.0  0.033130  0.068185        0.0  0.0   \n",
              "31       100.0       200.0  0.000000  0.000000        0.0  0.0   \n",
              "56       100.0       200.0  0.000000  0.000000        0.0  0.0   \n",
              "..         ...         ...       ...       ...        ...  ...   \n",
              "70         NaN         NaN  0.000000  0.000000        0.0  0.0   \n",
              "76         NaN         NaN  0.036686  0.075505        0.0  0.0   \n",
              "77         NaN         NaN  0.000000  0.000000        0.0  0.0   \n",
              "78         NaN         NaN  0.039157  0.080590        0.0  0.0   \n",
              "79         NaN         NaN  0.000000  0.000000        0.0  0.0   \n",
              "\n",
              "    00applications  00salary  00summary  00the  ...   youhave      your  \\\n",
              "67             0.0       0.0        0.0    0.0  ...  0.000000  0.008027   \n",
              "26             0.0       0.0        0.0    0.0  ...  0.000000  0.000000   \n",
              "22             0.0       0.0        0.0    0.0  ...  0.000000  0.000000   \n",
              "31             0.0       0.0        0.0    0.0  ...  0.000000  0.000000   \n",
              "56             0.0       0.0        0.0    0.0  ...  0.000000  0.000000   \n",
              "..             ...       ...        ...    ...  ...       ...       ...   \n",
              "70             0.0       0.0        0.0    0.0  ...  0.000000  0.079688   \n",
              "76             0.0       0.0        0.0    0.0  ...  0.098938  0.016891   \n",
              "77             0.0       0.0        0.0    0.0  ...  0.000000  0.000000   \n",
              "78             0.0       0.0        0.0    0.0  ...  0.000000  0.054086   \n",
              "79             0.0       0.0        0.0    0.0  ...  0.000000  0.014752   \n",
              "\n",
              "    yourself  youtube        yr  yrsmandatory  yummy      zero  zoho  zone  \n",
              "67       0.0      0.0  0.000000           0.0    0.0  0.000000   0.0   0.0  \n",
              "26       0.0      0.0  0.075790           0.0    0.0  0.000000   0.0   0.0  \n",
              "22       0.0      0.0  0.036180           0.0    0.0  0.000000   0.0   0.0  \n",
              "31       0.0      0.0  0.000000           0.0    0.0  0.000000   0.0   0.0  \n",
              "56       0.0      0.0  0.000000           0.0    0.0  0.000000   0.0   0.0  \n",
              "..       ...      ...       ...           ...    ...       ...   ...   ...  \n",
              "70       0.0      0.0  0.000000           0.0    0.0  0.000000   0.0   0.0  \n",
              "76       0.0      0.0  0.040064           0.0    0.0  0.000000   0.0   0.0  \n",
              "77       0.0      0.0  0.000000           0.0    0.0  0.000000   0.0   0.0  \n",
              "78       0.0      0.0  0.042762           0.0    0.0  0.000000   0.0   0.0  \n",
              "79       0.0      0.0  0.000000           0.0    0.0  0.021602   0.0   0.0  \n",
              "\n",
              "[104 rows x 5002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f604282-70d1-47dd-9f36-87672e204ad6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000remote</th>\n",
              "      <th>004</th>\n",
              "      <th>00applications</th>\n",
              "      <th>00salary</th>\n",
              "      <th>00summary</th>\n",
              "      <th>00the</th>\n",
              "      <th>...</th>\n",
              "      <th>youhave</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrsmandatory</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zoho</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.069401</td>\n",
              "      <td>0.071417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075790</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.033130</td>\n",
              "      <td>0.068185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.036686</td>\n",
              "      <td>0.075505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098938</td>\n",
              "      <td>0.016891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.039157</td>\n",
              "      <td>0.080590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042762</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 5002 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f604282-70d1-47dd-9f36-87672e204ad6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f604282-70d1-47dd-9f36-87672e204ad6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f604282-70d1-47dd-9f36-87672e204ad6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea9e9c41-30fc-49af-8b63-14e4006fd361\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea9e9c41-30fc-49af-8b63-14e4006fd361')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea9e9c41-30fc-49af-8b63-14e4006fd361 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3f6193f7-381d-4c14-a731-1c4a41649ca3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f6193f7-381d-4c14-a731-1c4a41649ca3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test.tolist(), y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyY7KncM4Vf3",
        "outputId": "95d205a2-8198-498d-a67d-3ad3df5f8443"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.4719712687542771\n",
            "Mean Squared Error: 0.43326203180801814\n",
            "accuracy is 0.6363636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Mean Absolute Error: 0.47993065078666375\n",
        "Mean Squared Error: 0.3460654666605357\n",
        "accuracy is 0.6363636363636364\n",
        "\n",
        "TT Split RS 95: Mean Absolute Error: 0.5449295696118838\n",
        "Mean Squared error: 0.5375021723477539\n",
        "accuracy is 0.6363636363636364\n",
        "\n",
        "TT Split RS 13: Mean Absolute Error: 0.4485097307444198\n",
        "Mean Squared Error: 0.3790559124675783\n",
        "accuracy is 0.6818181818181818\n",
        "\n",
        "TT Split RS 21: Mean Absolute Error: 0.4227856724462283\n",
        "Mean Squared Error: 0.3112876514654064\n",
        "accuracy is 0.7272727272727273\n",
        "\n",
        "TT Split RS 507: Mean Absolute Error: 0.4719712687542771\n",
        "Mean Squared Error: 0.43326203180801814\n",
        "accuracy is 0.6363636363636364"
      ],
      "metadata": {
        "id": "8h44F-upUq6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes!!! After bumping into some road blocks, I finally got it working, and it's the best accuracy I have gotten using a legitimate approach. Accuracy (rounded predictions) of 64%, MAE of .48. If Linear Regression got better results, what about the Logisic Regression and Random Forest Classifier algorithms?"
      ],
      "metadata": {
        "id": "kjC4kNWbBrcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "# By default, LogisticRegression uses OvR for multi-class classification\n",
        "model = LogisticRegression(max_iter=10000)  # Increase max_iter for convergence if needed\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6vCSkuGFe9",
        "outputId": "a18e0316-fc0e-4ef8-b350-f3ddc30a97ff"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Mean Absolute Error: 0.5909090909090909\n",
            "Mean Squared Error: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.5\n",
        "Mean Squared Error: 0.6818181818181818\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.7272727272727273\n",
        "Mean Squared Error: 1.0909090909090908\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.4090909090909091\n",
        "Mean Squared Error: 0.5\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.4090909090909091\n",
        "Mean Absolute Error: 0.6818181818181818\n",
        "Mean Squared Error: 0.8636363636363636\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "Mean Squared Error: 0.7727272727272727"
      ],
      "metadata": {
        "id": "W00-qqccGzcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "CKaLaVEsuu9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e3d14a-8280-496e-bd84-b1721e57ccd5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "mae: 0.5909090909090909\n",
            "Mean Squared Error: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "mae: 0.45454545454545453\n",
        "Mean Squared Error: 0.5454545454545454\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.5454545454545454\n",
        "mae: 0.5909090909090909\n",
        "Mean Squared Error: 0.9090909090909091\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.5909090909090909\n",
        "mae: 0.4090909090909091\n",
        "Mean Squared Error: 0.4090909090909091\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "mae: 0.5454545454545454\n",
        "Mean Squared Error: 0.6363636363636364\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453\n",
        "mae: 0.6363636363636364\n",
        "Mean Squared Error: 0.7727272727272727"
      ],
      "metadata": {
        "id": "fObsahctVIUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact we see that this change in feature engineering had no impact on the RFC's accuracy or MAE whatsoever. Maybe we should try a different seed for our train-test split?\n",
        "\n",
        "How does a HistGradientBoostingClassifier model do with this hybrid feature engineering approach (which we will from here on refer to as FE approach 3)?"
      ],
      "metadata": {
        "id": "s8h83Udg0jot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Initialize the HistGradientBoostingClassifier\n",
        "clf = HistGradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR0sWZDH0rOl",
        "outputId": "8e64f6f0-6706-48b7-d944-6118916022f0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Mean Absolute Error: 0.5909090909090909\n",
            "Mean Squared Error: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy .727 MAE .318 MSE 0.4090909090909091\n",
        "\n",
        "TT Split RS 95: Accuracy .591, MAE .409 MSE 0.4090909090909091\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "Mean Squared Error: 0.6818181818181818\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.36363636363636365\n",
        "Mean Squared Error: 0.36363636363636365\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "Mean Squared Error: 0.7727272727272727\n",
        "\n",
        "We are seeing a good amount of variance with this model.\n",
        "\n",
        "First try with train-test-split random seed 42: Accuracy .727 MAE .318; We see that this adding of the salary columns into the dataframe that would be passed into the algorithm from FE approach 2 (which we are calling FE approach 3) didn't result in any changes to accuracy or MAE of the HGBC model on this particular train-test split.\n",
        "Second train-test-split RS 95: Accuracy .591, MAE .409\n"
      ],
      "metadata": {
        "id": "odkHZV_d1kOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Ts-sxb2gDJ",
        "outputId": "1d993cf8-7999-4401-af4f-bfa400170dc1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45454545454545453\n",
            "Mean Absolute Error: 0.7272727272727273\n",
            "Mean Squared Error: 1.0909090909090908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.3181818181818182\n",
        "Mean Absolute Error: 0.8181818181818182\n",
        "Mean Squared Error: 1.1363636363636365\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.3181818181818182\n",
        "Mean Absolute Error: 0.7272727272727273\n",
        "Mean Squared Error: 1.0909090909090908\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.36363636363636365\n",
        "Mean Absolute Error: 0.6818181818181818\n",
        "Mean Squared Error: 0.8636363636363636\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5454545454545454\n",
        "Mean Squared Error: 0.8636363636363636\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453\n",
        "Mean Absolute Error: 0.6363636363636364\n",
        "Mean Squared Error: 1.0909090909090908"
      ],
      "metadata": {
        "id": "180ow2P1TfjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUb9b-9B31uA",
        "outputId": "7161bd67-f4d4-486d-d91c-badd75ba7ef3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Mean Absolute Error: 0.5909090909090909\n",
            "Mean Squared Error: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.4090909090909091\n",
        "Mean Squared Error: 0.4090909090909091\n",
        "\n",
        "TT Split RS 95: Accuracy: 0.6818181818181818\n",
        "Mean Absolute Error: 0.3181818181818182\n",
        "Mean Squared Error: 0.3181818181818182\n",
        "\n",
        "TT Split RS 13: Accuracy: 0.36363636363636365\n",
        "Mean Absolute Error: 0.7272727272727273\n",
        "Mean Squared Error: 0.9090909090909091\n",
        "\n",
        "TT Split RS 21: Accuracy: 0.6363636363636364\n",
        "Mean Absolute Error: 0.36363636363636365\n",
        "Mean Squared Error: 0.36363636363636365\n",
        "\n",
        "TT Split RS 507: Accuracy: 0.5\n",
        "Mean Absolute Error: 0.5909090909090909\n",
        "Mean Squared Error: 0.772727272727272"
      ],
      "metadata": {
        "id": "OfmVUb82TsVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting. With this feature engineering approach 3, we don't get fantastic accuracy using XGBoost but our MAE is lower than we've seen it for this algorithm.\n",
        "\n",
        "Well, it looks like doing other train-test splits that this algorithm has a HIGH degree of variance with this data because for some splits our accuracy and error are good and for others they are awful."
      ],
      "metadata": {
        "id": "TAajIgQH4dIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 4: Initialize and Train the SVM Classifier\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # Example hyperparameters\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Classifier\n",
        "accuracy = svm_classifier.score(X_test_scaled, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezgSmlI5JdE",
        "outputId": "2948a36a-f5e1-46dc-9774-d3e1f14ced62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45454545454545453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TT Split RS 42: Accuracy: 0.5454545454545454\n",
        "TT Split RS 95: Accuracy: .5\n",
        "TT Split RS 13: Accuracy: 0.5909090909090909\n",
        "TT Split RS 21: Accuracy: 0.45454545454545453\n",
        "TT Split RS 507: Accuracy: 0.45454545454545453"
      ],
      "metadata": {
        "id": "dSeBXEc0T7Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice nothing changed for SVC on RS 42 with change in feature engineering."
      ],
      "metadata": {
        "id": "uH9qUUd15Suc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the classifier\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the regressor\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_regressor.predict(X_test)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Evaluate the mean squared error of the regressor\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mae)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S_HtOsa5WHr",
        "outputId": "22c3f507-b480-4800-9f08-3a89f0e9bbdb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3181818181818182\n",
            "Mean absolute Error: 0.7272727272727273\n",
            "Mean Squared Error: 0.8181818181818182\n",
            "Accuracy: 0.36363636363636365\n",
            "Mean absolute Error: 0.6272727272727271\n",
            "Mean Squared Error: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting, KNN Regressor did better, but KNN classifier did worse, with FE approach 3. It kinda makes sense, since we have in general observed regression models improving with FE approach 3 but not necessarily other kinds of models.\n",
        "Order:\n",
        "KNNC\n",
        "KNNR\n",
        "TT Split RS 42:\n",
        "Accuracy: 0.5\n",
        "Mean absolute Error: 0.5909090909090909\n",
        "Mean Squared Error: 0.8636363636363636\n",
        "Accuracy: 0.6363636363636364\n",
        "Mean absolute Error: 0.48181818181818187\n",
        "Mean Squared Error: 0.4563636363636364\n",
        "\n",
        "TT Split RS 95:\n",
        "Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.7272727272727273\n",
        "Mean Squared Error: 1.1818181818181819\n",
        "Accuracy: 0.45454545454545453\n",
        "Mean absolute Error: 0.7\n",
        "Mean Squared Error: 0.7363636363636364\n",
        "\n",
        "TT Split RS 13:\n",
        "Accuracy: 0.6363636363636364\n",
        "Mean absolute Error: 0.36363636363636365\n",
        "Mean Squared Error: 0.36363636363636365\n",
        "Accuracy: 0.5909090909090909\n",
        "Mean absolute Error: 0.4636363636363638\n",
        "Mean Squared Error: 0.38727272727272727\n",
        "\n",
        "TT Split RS 21:\n",
        "Accuracy: 0.4090909090909091\n",
        "Mean absolute Error: 0.6363636363636364\n",
        "Mean Squared Error: 0.7272727272727273\n",
        "Accuracy: 0.4090909090909091\n",
        "Mean absolute Error: 0.5818181818181819\n",
        "Mean Squared Error: 0.48363636363636364\n",
        "\n",
        "TT Split RS 507:\n",
        "Accuracy: 0.3181818181818182\n",
        "Mean absolute Error: 0.7272727272727273\n",
        "Mean Squared Error: 0.8181818181818182\n",
        "Accuracy: 0.36363636363636365\n",
        "Mean absolute Error: 0.6272727272727271\n",
        "Mean Squared Error: 0.58"
      ],
      "metadata": {
        "id": "DzAEIVxK5-wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want to get more accurate measurements of the accuracy of each of our models. We will start with the top performing models and go down the list. We will update model_leaderboard.md https://github.com/liamtabrams/LIRecommend/blob/main/discussion/model_leaderboard.md in the Github repo with our findings."
      ],
      "metadata": {
        "id": "pDWQ-UYOKuvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially, I tried to use built-in scikit learn APIs for doing K-Fold cross validation on my data, but since I either do TFIDF on my training set and transform my test set based on that process (FE 2) or calculate phrase embeddings from the training set and count cluster occurences, I would have to bake my feature engineering into the cross validation using an SKLearn pipeline. That will be nontrivial. Although I will probably opt to do this at some point, for now I will opt to change the seed setting when I call train_test_split and reevaluate models. I can do this myself 5 times, and use that as a rudimentary cross validation to get some accuracy score averages. Then I might look at mean squared error and AUC-ROC values for different models."
      ],
      "metadata": {
        "id": "2VMe9-j_RMDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should try to refine and improve our model evaluation techniques. So far we have done a rather preliminary analysis using one train-test split and only looking at accuracy and mean absolute error for the different models we try. We should also be looking at AUC scores for the ROC for each class in the target variable. Furthermore, instead of focusing on mean absolute error, I think trying to minimize mean squared error is more important than mean absolute error. We see from the predictions of the RFC above that when the label value was 0, the algorithm predicted a 2. Even if other predictions are spot on, this larger difference between prediction and reality should be penalized more greatly, and mean squared error would take care of that.\n",
        "\n",
        "Before we embark any further, let's have a quick discussion about random models and baseline accuracy.\n",
        "\n",
        "A random model would give an accuracy of 25% and a mean absolute error of 1.25. We feel like we are moving in the right direction but I am still relunctant to say so when I consider the class imbalance in the dataset, which has 50/107 2s, or 46.7% of the dataset is 2s. This means that if a model were to predict just 2 no matter what, it would have achieved a 50/107 = 46.7% accuracy, which is better than how some of the models we trained did! What would the MAE be, based on the distribution of values in the dataset? It would be 70/107 or .654, which is not much worse than how most of the models have been doing, and better than some. What should reasonable values for accuracy and mean absolute error (or better yet mean squared error) be then, for a model that has potential value? Obviously we need to strive for at least better than 46.7% accuracy and less than .654 MAE! So we have found several models that do better than that, like linear regression, random forest classifiers and regressors, XGBoost, KNN classifiers and regressors, and even decision trees and support vector machines. HistGradientBoostingClassifier did about the same as our majority class picking model and GaussianNaiveBayes did horrendously, doing about in between as well as a purely random model and our majority class model. We see below that this original dataset of 107 job postings is not the most balanced, as nearly half of the data points are 2, about a quarter are 3, about 15% are 1 and 10% are 0."
      ],
      "metadata": {
        "id": "F6GeGwFUDBqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_value_counts = df_copy['rating'].value_counts()\n",
        "\n",
        "print(ratings_value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDUcXTW_fFGt",
        "outputId": "8af32419-26e9-4f28-a776-c299e97ec878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating\n",
            "2    50\n",
            "3    26\n",
            "1    18\n",
            "0    13\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now look at the accuracy of our attempt at reproducing the ratings from the original set of job postings about 2 months later."
      ],
      "metadata": {
        "id": "1qdgzz2cMCyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "og_ratings_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "reproduce_ratings_path = \"drive/MyDrive/ReproduceRatings.csv\"\n",
        "\n",
        "og_ratings = pd.read_csv(og_ratings_path, header=None, names=['url', 'rating'])['rating'].tolist()\n",
        "reproduced_ratings = pd.read_csv(reproduce_ratings_path, header=None, names=['rating'])['rating'].tolist()\n",
        "\n",
        "assert len(og_ratings) == len(reproduced_ratings)\n",
        "\n",
        "num_correct = 0\n",
        "total_absolute_error = 0\n",
        "total_squared_error = 0\n",
        "for i in range(len(og_ratings)):\n",
        "  if og_ratings[i] == reproduced_ratings[i]:\n",
        "    num_correct += 1\n",
        "  else:\n",
        "    total_absolute_error += abs(og_ratings[i] - reproduced_ratings[i])\n",
        "    total_squared_error += (og_ratings[i] - reproduced_ratings[i])**2\n",
        "\n",
        "\n",
        "accuracy = num_correct/len(og_ratings)\n",
        "mean_absolute_error = total_absolute_error/len(og_ratings)\n",
        "mean_squared_error = total_squared_error/len(og_ratings)\n",
        "print(f\"accuracy is {accuracy}\")\n",
        "print(f\"mean absolute error is {mean_absolute_error}\")\n",
        "print(f\"mean squared error is {mean_squared_error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRKBIpk1MMfK",
        "outputId": "e74abcde-dcdb-4a6e-81e5-c8bf32b8328f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.6261682242990654\n",
            "mean absolute error is 0.37383177570093457\n",
            "mean squared error is 0.37383177570093457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that, just from 2-month drift in my job preferences as well as inherit subjectivity in this exercise of rating job postings, I myself was only able to predict the rating I gave to the job posting 2 months ago, using the scraped text files (which admittedly may have problematic information loss from the original job posting), at a 62.6% accuracy rate with a mean absolute error of .374. We also see that our mean squared error is the same as our mean absolute error indicating that none of our misses were off by more than 1 rating point. So obviously this would be a very good model, to have myself modeling my job preferences from 2 months ago! This also means that if I have a linear regression model that produced predictions at 66.4% accuracy, that's pretty good. The error of the linear regression model with FE approach 3 was .474 so noticeably larger than the error of me reproducing the original ratings, but that .474 number was close to the lowest error we saw for any of the models we did cross validation on.     "
      ],
      "metadata": {
        "id": "d7ZYGyXbvHLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's looking like I will choose to move forward with combining linear regression with feature engineering approach 3. However, we never looked at mean squared error, so we will do cross validation to get average MSE values for our top performing models. Naturally we will start at the top of our leaderboard with linear regression and FE approach 3, rerunning code cells from above and updating our tables with our results for MSE."
      ],
      "metadata": {
        "id": "xhd1CoF_wsm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, looking at MSE has only strengthened the conclusion that the linear regression model with FE approach 3 is the clear-cut best choice. Not only is the MSE of the linear regression less than its MAE, but the MSE of the linear regression model is only slightly larger than RR (reproducing ratings) after 2 months. For a compact summary of all results found in this notebook, see https://github.com/liamtabrams/LIRecommend/blob/main/discussion/model_leaderboard.md.  "
      ],
      "metadata": {
        "id": "IGkCqG9w-XV5"
      }
    }
  ]
}